{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b133d2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_critical_semantic_area(locationMap,img_orig):\n",
    "    locationMap = np.maximum(locationMap, 0)  # ReLU\n",
    "    locationMap=locationMap-locationMap.min()\n",
    "    locationMap = locationMap / locationMap.max()\n",
    "\n",
    "    plt.figure()\n",
    "    #img_show=cv2.cvtColor(img_orig,cv2.COLOR_BGR2RGB)\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(img_orig)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * locationMap), cv2.COLORMAP_JET) \n",
    "    heatmap_show=cv2.cvtColor(heatmap,cv2.COLOR_BGR2RGB)\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(heatmap_show)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    semantic_show =0.7* heatmap_show +  img_orig\n",
    "    semantic_show=np.clip((semantic_show/np.max(semantic_show)),0,1)\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(semantic_show)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    #plt.savefig('tar_'+savefile+'.jpg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b2481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grad_CAM_Plus_Plus(img_numpy,img_tensor,target_label,model):\n",
    "    final_conv_name = None\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            final_conv_name = name\n",
    "   \n",
    "    model_module_last_conv=None\n",
    "    for name,module in model.named_modules():\n",
    "        if name==final_conv_name:\n",
    "            model_module_last_conv=module\n",
    "    \n",
    "    feature_maps=[]\n",
    "    def hook_features(module,input,output): #forward hook feature\n",
    "        feature_maps.append(output)       \n",
    "    feature_gradients=[]\n",
    "    def hook_gradient(module, grad_input, grad_output):  #backward hook gradient\n",
    "        feature_gradients.append(grad_output[0].detach())\n",
    "\n",
    "    \n",
    "    hook1=model_module_last_conv.register_forward_hook(hook_features)#register forward hook\n",
    "    hook2=model_module_last_conv.register_backward_hook(hook_gradient)#register backward hook\n",
    "   \n",
    "    logits=model(img_tensor)\n",
    "    preds=Func.softmax(logits,dim=1)\n",
    "    probs,idx=preds.data.squeeze().sort(0,True)\n",
    "    probs=probs.data.cpu().numpy()\n",
    "    idx=idx.data.cpu().numpy()\n",
    "    i=np.where(idx==target_label)[0]\n",
    "   \n",
    "    model.zero_grad() \n",
    "    targ_class_pred= logits[0][idx[i][0]] #logits.shape=(1,1000)\n",
    "    targ_class_pred.backward(retain_graph=True) #backward pass for gradient\n",
    "    \n",
    "    feature_map = feature_maps[0].cpu().data.numpy().squeeze()\n",
    "    feature_gradient = feature_gradients[0].cpu().data.numpy().squeeze()\n",
    "    feature_gradient=np.maximum(feature_gradient,0)\n",
    "    \n",
    "    alpha_num=feature_gradient**2\n",
    "    alpha_den=2*(feature_gradient**2)+(feature_gradient**3)*(np.sum(feature_map, axis=(1,2))[:, np.newaxis, np.newaxis])\n",
    "    weight=(alpha_num/(alpha_den+1e-8))*feature_gradient\n",
    "    weight = np.mean(weight, axis=(1,2))\n",
    "    cam=feature_map * weight[:, np.newaxis, np.newaxis]  # [C,H,W]\n",
    "    cam = np.sum(cam, axis=0)  # [H,W]\n",
    "    \n",
    "    cam = cv2.resize(cam, size_sample)\n",
    "    cam = np.maximum(cam, 0)  # ReLU\n",
    "    cam=cam-cam.min()\n",
    "    cam = cam / cam.max()\n",
    "    hook1.remove()\n",
    "    hook2.remove()\n",
    "    \n",
    "    \n",
    "    show_critical_semantic_area(cam,img_numpy)\n",
    "    return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6282d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Class_Saliency_Map(img_numpy,img_tensor,target_label,model):\n",
    "    img_tensor.requires_grad = True    \n",
    "    model_output =model(img_tensor)\n",
    "    model.zero_grad()\n",
    "    pred_class = model_output.argmax().item()\n",
    "    \n",
    "    preds=Func.softmax(model_output,dim=1)\n",
    "    probs,idx=preds.data.squeeze().sort(0,True)\n",
    "    probs=probs.data.cpu().numpy()\n",
    "    idx=idx.data.cpu().numpy()\n",
    "    i=np.where(idx==target_label)[0]  #index of target class\n",
    "    #print('{:.3f}->{}:{}\\n---------------'.format(probs[i][0],idx[i][0],class_label[idx[i][0]]))\n",
    "\n",
    "    grad_target_map = torch.zeros(model_output.shape, dtype=torch.float)\n",
    "    grad_target_map[0][target_label] = 1\n",
    " \n",
    "    model_output.backward(grad_target_map.to(device))\n",
    "    bp_m =img_tensor.grad.data[0].cpu().data.numpy().squeeze()\n",
    "    bp_m = np.sum(bp_m, axis=0)  # [H,W]\n",
    "    bp_m = np.maximum(bp_m, 0)  # ReLU\n",
    "    bp_m=bp_m-bp_m.min()\n",
    "    bp_m = bp_m / bp_m.max() #min-max normalization  \n",
    "    \n",
    "    show_critical_semantic_area(bp_m,img_numpy)\n",
    "    return bp_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013d3396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Guided_Backpropagation(img_numpy,img_tensor,target_label,model):\n",
    "    \n",
    "    image_reconstruction=[]\n",
    "    def first_layer_hook_fn(module, grad_in, grad_out):\n",
    "        image_reconstruction.append(grad_in[0])  #the first conv layer\n",
    "\n",
    "    activation_maps=[]\n",
    "    def forward_hook_fn(module, input, output):\n",
    "        activation_maps.append(output)\n",
    "\n",
    "    def backward_hook_fn(module, grad_in, grad_out):\n",
    "        grad = activation_maps.pop() \n",
    "        grad[grad > 0] = 1      \n",
    "        positive_grad_out = torch.clamp(grad_out[0], min=0.0)   \n",
    "        new_grad_in = positive_grad_out * grad\n",
    "        return (new_grad_in,)\n",
    "\n",
    "        \n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.ReLU):\n",
    "            hook_1=module.register_forward_hook(forward_hook_fn)\n",
    "            hook_2=module.register_backward_hook(backward_hook_fn)\n",
    "            \n",
    "            hook_1.remove()\n",
    "            hook_2.remove()\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            first_layer = module\n",
    "            hook_3=first_layer.register_backward_hook(first_layer_hook_fn)\n",
    "            break\n",
    "            \n",
    "            hook_3.remove()\n",
    "\n",
    "    model_output = model(img_tensor)\n",
    "    model.zero_grad()\n",
    "    pred_class = model_output.argmax().item()\n",
    "    \n",
    "    preds=Func.softmax(model_output,dim=1)\n",
    "    probs,idx=preds.data.squeeze().sort(0,True)\n",
    "    probs=probs.data.cpu().numpy()\n",
    "    idx=idx.data.cpu().numpy()\n",
    "    i=np.where(idx==target_label)[0]  \n",
    " \n",
    "    grad_target_map = torch.zeros(model_output.shape, dtype=torch.float)\n",
    "    grad_target_map[0][target_label] = 1\n",
    "\n",
    "        \n",
    "    model_output.backward(grad_target_map.to(device))\n",
    "    gbp_m = image_reconstruction[0].data[0].cpu().data.numpy().squeeze()\n",
    "    gbp_m = np.sum(gbp_m, axis=0)  \n",
    "    gbp_m = np.maximum(gbp_m, 0)  \n",
    "    gbp_m=gbp_m-gbp_m.min()\n",
    "    gbp_m = gbp_m / gbp_m.max()\n",
    "    \n",
    "    \n",
    "    show_critical_semantic_area(gbp_m,img_numpy)\n",
    "    return gbp_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4baba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Semantic_Fusion_Algorithm(image_path,target_label,model): \n",
    "    img_numpy,tensor_img=input_image(image_path)\n",
    "    img_tensor=Variable(torch.from_numpy(tensor_img).to(device).float())\n",
    "    original_label=np.argmax(model(img_tensor).data.cpu().numpy())    \n",
    "    #generate grad-cam++\n",
    "    grad_cam_plus_o1=Grad_CAM_Plus_Plus(img_numpy,img_tensor,original_label,model)\n",
    "    grad_cam_plus_t1=Grad_CAM_Plus_Plus(img_numpy,img_tensor,target_label,model)    \n",
    "    #generate saliency_map\n",
    "    saliency_m_o2=Class_Saliency_Map(img_numpy,img_tensor,original_label,model)\n",
    "    saliency_m_t2=Class_Saliency_Map(img_numpy,img_tensor,target_label,model)\n",
    "    #generate guided_bp\n",
    "    guided_bp_m_o3=Guided_Backpropagation(img_numpy,img_tensor,original_label,model) \n",
    "    guided_bp_m_t3=Guided_Backpropagation(img_numpy,img_tensor,target_label,model)\n",
    "    \n",
    "\n",
    "    SemanticR_o3=np.where(guided_bp_m_o3>0.1,guided_bp_m_o3,0)   \n",
    "    SemanticR_o2=np.where(saliency_m_o2>0.1,saliency_m_o2,0)  \n",
    "    SemanticR_o1=np.where(grad_cam_plus_o1>0.8,grad_cam_plus_o1,0)   \n",
    "\n",
    "    SemanticR_o=SemanticR_o1+SemanticR_o2+SemanticR_o3\n",
    "    SemanticR_o=SemanticR_o-SemanticR_o.min()\n",
    "    SemanticR_o=SemanticR_o/SemanticR_o.max()\n",
    "    show_critical_semantic_area(SemanticR_o,img_numpy)\n",
    "\n",
    "\n",
    "\n",
    "    SemanticR_t3=np.where(guided_bp_m_t3>0.2,guided_bp_m_t3,0)  \n",
    "    SemanticR_t2=np.where(saliency_m_t2>0.2,saliency_m_t2,0)  \n",
    "    SemanticR_t1=np.where(grad_cam_plus_t1>0.5,grad_cam_plus_t1,0)  \n",
    "\n",
    "    SemanticR_t=SemanticR_t1+SemanticR_t2+SemanticR_t3\n",
    "    SemanticR_t=SemanticR_t-SemanticR_t.min()\n",
    "    SemanticR_t=SemanticR_t/SemanticR_t.max()\n",
    "    semantic_area_show(SemanticR_t,img_numpy)\n",
    "\n",
    "\n",
    "    SemanticR=SemanticR_o+SemanticR_t-SemanticR_o*SemanticR_t*2.5\n",
    "    SemanticR=SemanticR-SemanticR.min()\n",
    "    SemanticR=SemanticR/SemanticR.max()\n",
    "    show_critical_semantic_area(SemanticR,img_numpy)\n",
    "\n",
    "    Semantic_mask=np.zeros_like(img_tensor.data.cpu().numpy())\n",
    "    Semantic_mask[:,:2,np.where(SemanticR>0)]=1\n",
    "    return  Semantic_mask,img_numpy, SemanticR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94712ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adapted_Adam_BFGS_Algorithm(model,img,orig_label,target_label,Semantic_mask,EPOCH,PerRge):\n",
    "    target=Variable(torch.from_numpy(np.eye(1000)[target_label]).to(device).float()) #one-hot code\n",
    "    targetlabel=Variable(torch.Tensor([float(target_label)]).to(device).long())\n",
    "\n",
    "    theta=0.2\n",
    "    #define the bound\n",
    "    max_=3.0\n",
    "    min_= -3.0 \n",
    "    imgo=img.data.cpu().numpy().copy()\n",
    "\n",
    "    img_max= imgo+PerRge\n",
    "    img_min=imgo-PerRge\n",
    "    \n",
    "    m=np.zeros_like(img.data.cpu().numpy())\n",
    "    v=np.zeros_like(img.data.cpu().numpy())    \n",
    "    D=np.identity(img.data.cpu().numpy().shape[2])\n",
    "    beta1=0.9\n",
    "    beta2=0.999\n",
    "    lr=0.1\n",
    "    eps=1e-08\n",
    "    k=10       \n",
    "    mask = np.ones_like(img.data.cpu().numpy())  \n",
    "    \n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "                   \n",
    "        output=model(img.to(torch.float32))\n",
    "        label=np.argmax(output.data.cpu().numpy())\n",
    "        zero_gradients(img)\n",
    "        \n",
    "        real=torch.max(output*target)\n",
    "        other=torch.max((1-target)*output)\n",
    "        loss=other-real+k\n",
    "        loss=torch.clamp(loss,min=0)\n",
    "        loss.backward(retain_graph=True)\n",
    "        \n",
    "  \n",
    "        if label ==target_label: \n",
    "            \n",
    "            print(\"Iter={} label={}->{} loss={:.6f}\\n-------------------------------\".format(iter, orig_label,label,loss))\n",
    "            print(\"Attack successfully!\")\n",
    "            break            \n",
    "       \n",
    "\n",
    "        gradient=img.grad.data.cpu().numpy().copy()\n",
    "        gradient_pre=gradient\n",
    "        \n",
    "        gradient = gradient * mask*Semantic_mask\n",
    "        idx = np.argmax(gradient)        \n",
    "        idx = np.unravel_index(idx, mask.shape)        \n",
    "        if epoch%10==0:\n",
    "            print(f\"Epoch {epoch}\")\n",
    "            print(idx)\n",
    "            print(\"label:{}->{} loss={:.6f}\\n-------------------------------\".format(orig_label,label,loss))\n",
    "            \n",
    "        m=beta1*m+(1-beta1)*gradient\n",
    "        v=beta2*v+(1-beta2)*(gradient**2)\n",
    "        mm=m/(1-beta1**(epoch+1))\n",
    "        vv=v/(1-beta2**(epoch+1))\n",
    "        #mask transformation\n",
    "        gradient=lr*np.matmul(D,(mm/(np.sqrt(vv)+eps)))\n",
    "\n",
    "        img_pre=img     \n",
    "        img.data[idx]=img.data[idx]-gradient[idx] #* theta * (max_ - min_) \n",
    "        \n",
    "        output=model(img)\n",
    "        real=torch.max(output*target)\n",
    "        other=torch.max((1-target)*output)\n",
    "        loss=other-real+k\n",
    "        loss=torch.clamp(loss,min=0)\n",
    "        loss.backward(retain_graph=True)    \n",
    "        gradient=img.grad.data.cpu().numpy().copy()\n",
    "        \n",
    "       \n",
    "        sk=img.data.cpu().numpy()-img_pre.data.cpu().numpy()\n",
    "        yk=gradient-gradient_pre\n",
    "        \n",
    "        rk=1/(np.matmul(np.transpose(yk,(0,1,3,2)),sk)+1e-10)\n",
    "        term1=rk*np.matmul(sk,np.transpose(yk,(0,1,3,2)))\n",
    "        term2=rk*np.matmul(yk,np.transpose(sk,(0,1,3,2)))\n",
    "        I=np.identity(img.data.cpu().numpy().shape[2])\n",
    "        term3=np.matmul(I-term1,D)\n",
    "        term4=np.matmul(term3,I-term2)\n",
    "        term5=rk*np.matmul(sk,np.transpose(sk,(0,1,3,2)))\n",
    "        D=term4+term5  \n",
    "            \n",
    "        if (img.data[idx]<=img_min[idx]) or (img.data[idx]>=img_max[idx]):\n",
    "            print(\"idx={} over {:.6f},{:.6f},{:.6f}\".format(idx,img.data[idx],img_min[idx],img_max[idx]))\n",
    "            mask[idx]=0\n",
    "            img.data[idx]=np.clip(img.data[idx].cpu(), img_min[idx], img_max[idx]) \n",
    "        \n",
    "        if (img.data[idx]<=min_) or (img.data[idx]>=max_):\n",
    "            print(\"idx={} over {:.6f},{:.6f},{:.6f\".format(idx,img.data[idx].cpu(),min_,max_))\n",
    "            mask[idx]=0\n",
    "            img.data[idx]=np.clip(img.data[idx], min_, max_)\n",
    "    return img,label,imgo,epoch+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b248a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Targeted_Attack_SFGA(img,model, target_label,Semantic_mask,EPOCH,PerRge):\n",
    "    orig_label=np.argmax(model(img).data.cpu().numpy())\n",
    "    print(\"orig_label={}:{}\".format(orig_label,class_label[orig_label]))    \n",
    "    img.requires_grad = True\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "   \n",
    "    \n",
    "    adv_img,label,imgo,epoch=Adapted_Adam_BFGS_Algorithm(model,img,orig_label,target_label,Semantic_mask,EPOCH,PerRge)  #   gradient_adam  #gradient_backpropagation  \n",
    "        \n",
    "    preds_=Func.softmax(model(adv_img),dim=1)\n",
    "    probs_,idx_=preds_.data.squeeze().sort(0,True)\n",
    "    probs_=probs_.data.cpu().numpy()\n",
    "    idx_=idx_.data.cpu().numpy()\n",
    "    for k_ in range(10):\n",
    "        print('{}, {},  {:.5f}, {}'.format(k_+1, idx_[k_], probs_[k_], class_label[idx_[k_]]))   \n",
    "    \n",
    "    \n",
    "    adv= adv_img.data.cpu().numpy()[0]\n",
    "    adv = adv.transpose(1, 2, 0)\n",
    "\n",
    "    adv = (adv * std) + mean\n",
    "    adv = adv * 256.0\n",
    "    adv = np.clip(adv, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"original {}:{}\".format(orig_label,class_label[orig_label]))\n",
    "    print(\"current {}:{}\".format(label,class_label[label]))\n",
    "    return orig_label,adv,label,epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24269234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
